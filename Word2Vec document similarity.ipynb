{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f99074e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Deep learning:\n",
    "# from tensorflow.python.keras.models import Input\n",
    "\n",
    "from keras.layers import Input, Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "\n",
    "from keras.models import Model\n",
    "\n",
    "# from keras.models import Input, Model\n",
    "\n",
    "from scipy import sparse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4ea22ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "document1 = \"Machine learning (ML) is a field of inquiry devoted to understanding and building methods that 'learn', that is, methods that leverage data to improve performance on some set of tasks.[1] It is seen as a part of artificial intelligence. Machine learning algorithms build a model based on sample data, known as training data, in order to make predictions or decisions without being explicitly programmed to do so.[2] Machine learning algorithms are used in a wide variety of applications, such as in medicine, email filtering, speech recognition, agriculture, and computer vision, where it is difficult or unfeasible to develop conventional algorithms to perform the needed tasks.[3][4] A subset of machine learning is closely related to computational statistics, which focuses on making predictions using computers, but not all machine learning is statistical learning. The study of mathematical optimization delivers methods, theory and application domains to the field of machine learning. Data mining is a related field of study, focusing on exploratory data analysis through unsupervised learning.[6][7] Some implementations of machine learning use data and neural networks in a way that mimics the working of a biological brain.[8][9] In its application across business problems, machine learning is also referred to as predictive analytics.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9533a57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The future king is the prince</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Daughter is the princess</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Son is the prince</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Only a man can be a king</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Only a woman can be a queen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The princess will be a queen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Queen and king rule the realm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The prince is a strong man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The princess is a beautiful woman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The royal family is the king and queen and the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Prince is only a boy now</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>A boy will be a man</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text\n",
       "0                       The future king is the prince\n",
       "1                           Daughter is the princess \n",
       "2                                   Son is the prince\n",
       "3                           Only a man can be a king \n",
       "4                         Only a woman can be a queen\n",
       "5                        The princess will be a queen\n",
       "6                       Queen and king rule the realm\n",
       "7                          The prince is a strong man\n",
       "8                  The princess is a beautiful woman \n",
       "9   The royal family is the king and queen and the...\n",
       "10                           Prince is only a boy now\n",
       "11                                A boy will be a man"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = pd.read_csv(\"E:\\\\College\\\\FCAI-4th Year\\\\First Term\\\\Generative Adversarial Networks\\\\Lab Codes\\\\TextNLP.csv\")\n",
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00376dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "['The future king is the prince', 'Daughter is the princess ', 'Son is the prince', 'Only a man can be a king ', 'Only a woman can be a queen', 'The princess will be a queen', 'Queen and king rule the realm', 'The prince is a strong man', 'The princess is a beautiful woman ', 'The royal family is the king and queen and their children', 'Prince is only a boy now', 'A boy will be a man']\n"
     ]
    }
   ],
   "source": [
    "texts = [x for x in texts['text']]\n",
    "print(len(texts))\n",
    "print(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc0ef5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocessing(\n",
    "        text: list,\n",
    "        punctuations=r'''!()-[]{};:'\"\\,<>./?@#$%^&*_â€œ~''',\n",
    "        stop_words=['and', 'a', 'is', 'the', 'in', 'be', 'will', 'was', 'but', 'this', 'were', 'with', 'of', 'also',\n",
    "                    'on', '.', 'for', 'any', 'its', 'and', 'are', 'from', 'both', 'as']\n",
    ") -> list:\n",
    "    \"\"\"\n",
    "    A method to preproces text\n",
    "    \"\"\"\n",
    "    for x in text.lower():\n",
    "        if x in punctuations:\n",
    "            text = text.replace(x, \"\")\n",
    "\n",
    "    # Removing words that have numbers in them\n",
    "    text = re.sub(r'\\w*\\d\\w*', '', text)\n",
    "\n",
    "    # Removing digits\n",
    "    text = re.sub(r'[0-9]+', '', text)\n",
    "\n",
    "    # Cleaning the whitespaces\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    # Setting every word to lower\n",
    "    text = text.lower()\n",
    "\n",
    "    # Converting all our text to a list \n",
    "    text = text.split(' ')\n",
    "\n",
    "    # Droping empty strings\n",
    "    text = [x for x in text if x != '']\n",
    "\n",
    "    # Droping stop words\n",
    "    text = [x for x in text if x not in stop_words]\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6e57aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 4\n",
    "# Creating a placeholder for the scanning of the word list\n",
    "word_lists = []\n",
    "all_text = []\n",
    "for text in texts:\n",
    "\n",
    "    # Cleaning the text\n",
    "    text = text_preprocessing(text)\n",
    "    # print (text)\n",
    "\n",
    "    # Appending to the all text list\n",
    "    all_text += text\n",
    "\n",
    "    # Creating a context dictionary\n",
    "    for i, word in enumerate(text):\n",
    "        for w in range(window):\n",
    "            # Getting the context that is ahead by *window* words\n",
    "            if i + 1 + w < len(text):\n",
    "                word_lists.append([word] + [text[(i + 1 + w)]])\n",
    "            # Getting the context that is behind by *window* words\n",
    "            if i - w - 1 >= 0:\n",
    "                word_lists.append([word] + [text[(i - w - 1)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6350043",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_unique_word_dict(text: list) -> dict:\n",
    "    \"\"\"\n",
    "    A method that creates a dictionary where the keys are unique words\n",
    "    and key values are indices\n",
    "    \"\"\"\n",
    "    # Getting all the unique words from our text and sorting them alphabetically\n",
    "    words = list(set(text))\n",
    "    words.sort()\n",
    "\n",
    "    # Creating the dictionary for the unique words\n",
    "    unique_word_dict = {}\n",
    "    for i, word in enumerate(words):\n",
    "        unique_word_dict.update({\n",
    "            word: i\n",
    "        })\n",
    "\n",
    "    return unique_word_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd3dd796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'beautiful': 0, 'boy': 1, 'can': 2, 'children': 3, 'daughter': 4, 'family': 5, 'future': 6, 'king': 7, 'man': 8, 'now': 9, 'only': 10, 'prince': 11, 'princess': 12, 'queen': 13, 'realm': 14, 'royal': 15, 'rule': 16, 'son': 17, 'strong': 18, 'their': 19, 'woman': 20}\n",
      "['beautiful', 'boy', 'can', 'children', 'daughter', 'family', 'future', 'king', 'man', 'now', 'only', 'prince', 'princess', 'queen', 'realm', 'royal', 'rule', 'son', 'strong', 'their', 'woman']\n",
      "21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "102it [00:00, 52185.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['future', 'king']\n",
      "future 6\n",
      "king 7\n",
      "['future', 'prince']\n",
      "future 6\n",
      "prince 11\n",
      "['king', 'prince']\n",
      "king 7\n",
      "prince 11\n",
      "['king', 'future']\n",
      "king 7\n",
      "future 6\n",
      "['prince', 'king']\n",
      "prince 11\n",
      "king 7\n",
      "['prince', 'future']\n",
      "prince 11\n",
      "future 6\n",
      "['daughter', 'princess']\n",
      "daughter 4\n",
      "princess 12\n",
      "['princess', 'daughter']\n",
      "princess 12\n",
      "daughter 4\n",
      "['son', 'prince']\n",
      "son 17\n",
      "prince 11\n",
      "['prince', 'son']\n",
      "prince 11\n",
      "son 17\n",
      "['only', 'man']\n",
      "only 10\n",
      "man 8\n",
      "['only', 'can']\n",
      "only 10\n",
      "can 2\n",
      "['only', 'king']\n",
      "only 10\n",
      "king 7\n",
      "['man', 'can']\n",
      "man 8\n",
      "can 2\n",
      "['man', 'only']\n",
      "man 8\n",
      "only 10\n",
      "['man', 'king']\n",
      "man 8\n",
      "king 7\n",
      "['can', 'king']\n",
      "can 2\n",
      "king 7\n",
      "['can', 'man']\n",
      "can 2\n",
      "man 8\n",
      "['can', 'only']\n",
      "can 2\n",
      "only 10\n",
      "['king', 'can']\n",
      "king 7\n",
      "can 2\n",
      "['king', 'man']\n",
      "king 7\n",
      "man 8\n",
      "['king', 'only']\n",
      "king 7\n",
      "only 10\n",
      "['only', 'woman']\n",
      "only 10\n",
      "woman 20\n",
      "['only', 'can']\n",
      "only 10\n",
      "can 2\n",
      "['only', 'queen']\n",
      "only 10\n",
      "queen 13\n",
      "['woman', 'can']\n",
      "woman 20\n",
      "can 2\n",
      "['woman', 'only']\n",
      "woman 20\n",
      "only 10\n",
      "['woman', 'queen']\n",
      "woman 20\n",
      "queen 13\n",
      "['can', 'queen']\n",
      "can 2\n",
      "queen 13\n",
      "['can', 'woman']\n",
      "can 2\n",
      "woman 20\n",
      "['can', 'only']\n",
      "can 2\n",
      "only 10\n",
      "['queen', 'can']\n",
      "queen 13\n",
      "can 2\n",
      "['queen', 'woman']\n",
      "queen 13\n",
      "woman 20\n",
      "['queen', 'only']\n",
      "queen 13\n",
      "only 10\n",
      "['princess', 'queen']\n",
      "princess 12\n",
      "queen 13\n",
      "['queen', 'princess']\n",
      "queen 13\n",
      "princess 12\n",
      "['queen', 'king']\n",
      "queen 13\n",
      "king 7\n",
      "['queen', 'rule']\n",
      "queen 13\n",
      "rule 16\n",
      "['queen', 'realm']\n",
      "queen 13\n",
      "realm 14\n",
      "['king', 'rule']\n",
      "king 7\n",
      "rule 16\n",
      "['king', 'queen']\n",
      "king 7\n",
      "queen 13\n",
      "['king', 'realm']\n",
      "king 7\n",
      "realm 14\n",
      "['rule', 'realm']\n",
      "rule 16\n",
      "realm 14\n",
      "['rule', 'king']\n",
      "rule 16\n",
      "king 7\n",
      "['rule', 'queen']\n",
      "rule 16\n",
      "queen 13\n",
      "['realm', 'rule']\n",
      "realm 14\n",
      "rule 16\n",
      "['realm', 'king']\n",
      "realm 14\n",
      "king 7\n",
      "['realm', 'queen']\n",
      "realm 14\n",
      "queen 13\n",
      "['prince', 'strong']\n",
      "prince 11\n",
      "strong 18\n",
      "['prince', 'man']\n",
      "prince 11\n",
      "man 8\n",
      "['strong', 'man']\n",
      "strong 18\n",
      "man 8\n",
      "['strong', 'prince']\n",
      "strong 18\n",
      "prince 11\n",
      "['man', 'strong']\n",
      "man 8\n",
      "strong 18\n",
      "['man', 'prince']\n",
      "man 8\n",
      "prince 11\n",
      "['princess', 'beautiful']\n",
      "princess 12\n",
      "beautiful 0\n",
      "['princess', 'woman']\n",
      "princess 12\n",
      "woman 20\n",
      "['beautiful', 'woman']\n",
      "beautiful 0\n",
      "woman 20\n",
      "['beautiful', 'princess']\n",
      "beautiful 0\n",
      "princess 12\n",
      "['woman', 'beautiful']\n",
      "woman 20\n",
      "beautiful 0\n",
      "['woman', 'princess']\n",
      "woman 20\n",
      "princess 12\n",
      "['royal', 'family']\n",
      "royal 15\n",
      "family 5\n",
      "['royal', 'king']\n",
      "royal 15\n",
      "king 7\n",
      "['royal', 'queen']\n",
      "royal 15\n",
      "queen 13\n",
      "['royal', 'their']\n",
      "royal 15\n",
      "their 19\n",
      "['family', 'king']\n",
      "family 5\n",
      "king 7\n",
      "['family', 'royal']\n",
      "family 5\n",
      "royal 15\n",
      "['family', 'queen']\n",
      "family 5\n",
      "queen 13\n",
      "['family', 'their']\n",
      "family 5\n",
      "their 19\n",
      "['family', 'children']\n",
      "family 5\n",
      "children 3\n",
      "['king', 'queen']\n",
      "king 7\n",
      "queen 13\n",
      "['king', 'family']\n",
      "king 7\n",
      "family 5\n",
      "['king', 'their']\n",
      "king 7\n",
      "their 19\n",
      "['king', 'royal']\n",
      "king 7\n",
      "royal 15\n",
      "['king', 'children']\n",
      "king 7\n",
      "children 3\n",
      "['queen', 'their']\n",
      "queen 13\n",
      "their 19\n",
      "['queen', 'king']\n",
      "queen 13\n",
      "king 7\n",
      "['queen', 'children']\n",
      "queen 13\n",
      "children 3\n",
      "['queen', 'family']\n",
      "queen 13\n",
      "family 5\n",
      "['queen', 'royal']\n",
      "queen 13\n",
      "royal 15\n",
      "['their', 'children']\n",
      "their 19\n",
      "children 3\n",
      "['their', 'queen']\n",
      "their 19\n",
      "queen 13\n",
      "['their', 'king']\n",
      "their 19\n",
      "king 7\n",
      "['their', 'family']\n",
      "their 19\n",
      "family 5\n",
      "['their', 'royal']\n",
      "their 19\n",
      "royal 15\n",
      "['children', 'their']\n",
      "children 3\n",
      "their 19\n",
      "['children', 'queen']\n",
      "children 3\n",
      "queen 13\n",
      "['children', 'king']\n",
      "children 3\n",
      "king 7\n",
      "['children', 'family']\n",
      "children 3\n",
      "family 5\n",
      "['prince', 'only']\n",
      "prince 11\n",
      "only 10\n",
      "['prince', 'boy']\n",
      "prince 11\n",
      "boy 1\n",
      "['prince', 'now']\n",
      "prince 11\n",
      "now 9\n",
      "['only', 'boy']\n",
      "only 10\n",
      "boy 1\n",
      "['only', 'prince']\n",
      "only 10\n",
      "prince 11\n",
      "['only', 'now']\n",
      "only 10\n",
      "now 9\n",
      "['boy', 'now']\n",
      "boy 1\n",
      "now 9\n",
      "['boy', 'only']\n",
      "boy 1\n",
      "only 10\n",
      "['boy', 'prince']\n",
      "boy 1\n",
      "prince 11\n",
      "['now', 'boy']\n",
      "now 9\n",
      "boy 1\n",
      "['now', 'only']\n",
      "now 9\n",
      "only 10\n",
      "['now', 'prince']\n",
      "now 9\n",
      "prince 11\n",
      "['boy', 'man']\n",
      "boy 1\n",
      "man 8\n",
      "['man', 'boy']\n",
      "man 8\n",
      "boy 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "unique_word_dict = create_unique_word_dict(all_text)\n",
    "# Defining the number of features (unique words)\n",
    "n_words = len(unique_word_dict)\n",
    "print(unique_word_dict)\n",
    "\n",
    "# Getting all the unique words\n",
    "words = list(unique_word_dict.keys())\n",
    "print(words)\n",
    "\n",
    "# Creating the X and Y matrices using one hot encoding\n",
    "print(n_words)\n",
    "X = []\n",
    "Y = []\n",
    "for i, word_list in tqdm(enumerate(word_lists)):\n",
    "    # Getting the indices\n",
    "    print(word_list)\n",
    "    main_word_index = unique_word_dict.get(word_list[0])\n",
    "    context_word_index = unique_word_dict.get(word_list[1])\n",
    "    # print (word_list)\n",
    "    print(word_list[0], main_word_index)\n",
    "    print(word_list[1], context_word_index)\n",
    "\n",
    "    # Creating the placeholders\n",
    "    X_row = np.zeros(n_words)\n",
    "    Y_row = np.zeros(n_words)\n",
    "\n",
    "    # One hot encoding the main word\n",
    "    X_row[main_word_index] = 1\n",
    "\n",
    "    # One hot encoding the Y matrix words\n",
    "    Y_row[context_word_index] = 1\n",
    "\n",
    "    # Appending to the main matrices\n",
    "    X.append(X_row)\n",
    "    Y.append(Y_row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78c6c537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       1., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 1.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 1.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 1.]), array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 1., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 1., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 1.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 1.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 1., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 1., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 1., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 1., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 1., 0.]), array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.])]\n",
      "[array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       1., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 1.]), array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 1.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 1.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 1., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 1., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 1.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 1.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 1., 0.]), array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 1., 0.]), array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 1., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 1., 0.]), array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 1., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.]), array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.])]\n"
     ]
    }
   ],
   "source": [
    "print(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fa64ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(102, 21)\n",
      "(102, 21)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# X= sparse.csr_matrix(X)\n",
    "# Y = sparse.csr_matrix(Y)\n",
    "# print (X)\n",
    "# print(X[0, :].toarray())\n",
    "# print (X.todense())\n",
    "# a = X.todense()\n",
    "# print (a[0])\n",
    "XX = tf.convert_to_tensor(X, dtype=tf.float32)\n",
    "YY = tf.convert_to_tensor(Y, dtype=tf.float32)\n",
    "print(XX.shape)\n",
    "print(YY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c073f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateModel():\n",
    "    # Defining the size of the embedding\n",
    "    embed_size = 2\n",
    "    # Defining the neural network\n",
    "\n",
    "    # inp = Input(shape=(X.shape[1],))\n",
    "    inp = Input(shape=XX.shape[1])  # 21\n",
    "    x = Dense(units=embed_size, activation='linear')(inp)\n",
    "    # x = Dense(units=21, activation='softmax')(x)\n",
    "    x = Dense(units=YY.shape[1], activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=inp, outputs=x)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "568f8539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 21)]              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 44        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 21)                63        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 107\n",
      "Trainable params: 107\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3.0588\n",
      "Epoch 2/500\n",
      "11/11 [==============================] - 0s 997us/step - loss: 3.0539\n",
      "Epoch 3/500\n",
      "11/11 [==============================] - 0s 968us/step - loss: 3.0501\n",
      "Epoch 4/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3.0462\n",
      "Epoch 5/500\n",
      "11/11 [==============================] - 0s 998us/step - loss: 3.0429\n",
      "Epoch 6/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3.0394\n",
      "Epoch 7/500\n",
      "11/11 [==============================] - 0s 897us/step - loss: 3.0358\n",
      "Epoch 8/500\n",
      "11/11 [==============================] - 0s 997us/step - loss: 3.0322\n",
      "Epoch 9/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3.0288\n",
      "Epoch 10/500\n",
      "11/11 [==============================] - 0s 997us/step - loss: 3.0253\n",
      "Epoch 11/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3.0221\n",
      "Epoch 12/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3.0189\n",
      "Epoch 13/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3.0157\n",
      "Epoch 14/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3.0124\n",
      "Epoch 15/500\n",
      "11/11 [==============================] - 0s 997us/step - loss: 3.0093\n",
      "Epoch 16/500\n",
      "11/11 [==============================] - 0s 998us/step - loss: 3.0059\n",
      "Epoch 17/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3.0028\n",
      "Epoch 18/500\n",
      "11/11 [==============================] - 0s 1000us/step - loss: 2.9995\n",
      "Epoch 19/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.9962\n",
      "Epoch 20/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.9930\n",
      "Epoch 21/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.9900\n",
      "Epoch 22/500\n",
      "11/11 [==============================] - 0s 999us/step - loss: 2.9870\n",
      "Epoch 23/500\n",
      "11/11 [==============================] - 0s 901us/step - loss: 2.9837\n",
      "Epoch 24/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.9806\n",
      "Epoch 25/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.9776\n",
      "Epoch 26/500\n",
      "11/11 [==============================] - 0s 898us/step - loss: 2.9745\n",
      "Epoch 27/500\n",
      "11/11 [==============================] - 0s 798us/step - loss: 2.9717\n",
      "Epoch 28/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.9684\n",
      "Epoch 29/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.9658\n",
      "Epoch 30/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.9629\n",
      "Epoch 31/500\n",
      "11/11 [==============================] - 0s 897us/step - loss: 2.9603\n",
      "Epoch 32/500\n",
      "11/11 [==============================] - 0s 798us/step - loss: 2.9575\n",
      "Epoch 33/500\n",
      "11/11 [==============================] - 0s 997us/step - loss: 2.9553\n",
      "Epoch 34/500\n",
      "11/11 [==============================] - 0s 997us/step - loss: 2.9523\n",
      "Epoch 35/500\n",
      "11/11 [==============================] - 0s 895us/step - loss: 2.9498\n",
      "Epoch 36/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.9470\n",
      "Epoch 37/500\n",
      "11/11 [==============================] - 0s 999us/step - loss: 2.9443\n",
      "Epoch 38/500\n",
      "11/11 [==============================] - 0s 942us/step - loss: 2.9416\n",
      "Epoch 39/500\n",
      "11/11 [==============================] - 0s 900us/step - loss: 2.9389\n",
      "Epoch 40/500\n",
      "11/11 [==============================] - 0s 997us/step - loss: 2.9361\n",
      "Epoch 41/500\n",
      "11/11 [==============================] - 0s 995us/step - loss: 2.9333\n",
      "Epoch 42/500\n",
      "11/11 [==============================] - 0s 997us/step - loss: 2.9304\n",
      "Epoch 43/500\n",
      "11/11 [==============================] - 0s 800us/step - loss: 2.9280\n",
      "Epoch 44/500\n",
      "11/11 [==============================] - 0s 898us/step - loss: 2.9252\n",
      "Epoch 45/500\n",
      "11/11 [==============================] - 0s 797us/step - loss: 2.9227\n",
      "Epoch 46/500\n",
      "11/11 [==============================] - 0s 997us/step - loss: 2.9201\n",
      "Epoch 47/500\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 2.9177\n",
      "Epoch 48/500\n",
      "11/11 [==============================] - 0s 992us/step - loss: 2.9152\n",
      "Epoch 49/500\n",
      "11/11 [==============================] - 0s 698us/step - loss: 2.9125\n",
      "Epoch 50/500\n",
      "11/11 [==============================] - 0s 898us/step - loss: 2.9101\n",
      "Epoch 51/500\n",
      "11/11 [==============================] - 0s 898us/step - loss: 2.9076\n",
      "Epoch 52/500\n",
      "11/11 [==============================] - 0s 794us/step - loss: 2.9047\n",
      "Epoch 53/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.9023\n",
      "Epoch 54/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.8997\n",
      "Epoch 55/500\n",
      "11/11 [==============================] - 0s 898us/step - loss: 2.8967\n",
      "Epoch 56/500\n",
      "11/11 [==============================] - 0s 801us/step - loss: 2.8943\n",
      "Epoch 57/500\n",
      "11/11 [==============================] - 0s 898us/step - loss: 2.8914\n",
      "Epoch 58/500\n",
      "11/11 [==============================] - 0s 898us/step - loss: 2.8890\n",
      "Epoch 59/500\n",
      "11/11 [==============================] - 0s 758us/step - loss: 2.8863\n",
      "Epoch 60/500\n",
      "11/11 [==============================] - 0s 898us/step - loss: 2.8841\n",
      "Epoch 61/500\n",
      "11/11 [==============================] - 0s 999us/step - loss: 2.8818\n",
      "Epoch 62/500\n",
      "11/11 [==============================] - 0s 997us/step - loss: 2.8792\n",
      "Epoch 63/500\n",
      "11/11 [==============================] - 0s 898us/step - loss: 2.8769\n",
      "Epoch 64/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.8745\n",
      "Epoch 65/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.8724\n",
      "Epoch 66/500\n",
      "11/11 [==============================] - 0s 898us/step - loss: 2.8698\n",
      "Epoch 67/500\n",
      "11/11 [==============================] - 0s 798us/step - loss: 2.8675\n",
      "Epoch 68/500\n",
      "11/11 [==============================] - 0s 900us/step - loss: 2.8654\n",
      "Epoch 69/500\n",
      "11/11 [==============================] - 0s 898us/step - loss: 2.8626\n",
      "Epoch 70/500\n",
      "11/11 [==============================] - 0s 798us/step - loss: 2.8602\n",
      "Epoch 71/500\n",
      "11/11 [==============================] - 0s 885us/step - loss: 2.8577\n",
      "Epoch 72/500\n",
      "11/11 [==============================] - 0s 998us/step - loss: 2.8554\n",
      "Epoch 73/500\n",
      "11/11 [==============================] - 0s 698us/step - loss: 2.8530\n",
      "Epoch 74/500\n",
      "11/11 [==============================] - 0s 898us/step - loss: 2.8506\n",
      "Epoch 75/500\n",
      "11/11 [==============================] - 0s 852us/step - loss: 2.8482\n",
      "Epoch 76/500\n",
      "11/11 [==============================] - 0s 701us/step - loss: 2.8458\n",
      "Epoch 77/500\n",
      "11/11 [==============================] - 0s 898us/step - loss: 2.8435\n",
      "Epoch 78/500\n",
      "11/11 [==============================] - 0s 856us/step - loss: 2.8413\n",
      "Epoch 79/500\n",
      "11/11 [==============================] - 0s 798us/step - loss: 2.8390\n",
      "Epoch 80/500\n",
      "11/11 [==============================] - 0s 798us/step - loss: 2.8370\n",
      "Epoch 81/500\n",
      "11/11 [==============================] - 0s 798us/step - loss: 2.8346\n",
      "Epoch 82/500\n",
      "11/11 [==============================] - 0s 800us/step - loss: 2.8325\n",
      "Epoch 83/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.8306\n",
      "Epoch 84/500\n",
      "11/11 [==============================] - 0s 698us/step - loss: 2.8285\n",
      "Epoch 85/500\n",
      "11/11 [==============================] - 0s 800us/step - loss: 2.8266\n",
      "Epoch 86/500\n",
      "11/11 [==============================] - 0s 906us/step - loss: 2.8245\n",
      "Epoch 87/500\n",
      "11/11 [==============================] - 0s 701us/step - loss: 2.8226\n",
      "Epoch 88/500\n",
      "11/11 [==============================] - 0s 913us/step - loss: 2.8207\n",
      "Epoch 89/500\n",
      "11/11 [==============================] - 0s 698us/step - loss: 2.8189\n",
      "Epoch 90/500\n",
      "11/11 [==============================] - 0s 798us/step - loss: 2.8170\n",
      "Epoch 91/500\n",
      "11/11 [==============================] - 0s 896us/step - loss: 2.8148\n",
      "Epoch 92/500\n",
      "11/11 [==============================] - 0s 598us/step - loss: 2.8130\n",
      "Epoch 93/500\n",
      "11/11 [==============================] - 0s 798us/step - loss: 2.8111\n",
      "Epoch 94/500\n",
      "11/11 [==============================] - 0s 898us/step - loss: 2.8091\n",
      "Epoch 95/500\n",
      "11/11 [==============================] - 0s 722us/step - loss: 2.8069\n",
      "Epoch 96/500\n",
      "11/11 [==============================] - 0s 791us/step - loss: 2.8054\n",
      "Epoch 97/500\n",
      "11/11 [==============================] - 0s 597us/step - loss: 2.8032\n",
      "Epoch 98/500\n",
      "11/11 [==============================] - 0s 777us/step - loss: 2.8017\n",
      "Epoch 99/500\n",
      "11/11 [==============================] - 0s 798us/step - loss: 2.7999\n",
      "Epoch 100/500\n",
      "11/11 [==============================] - 0s 798us/step - loss: 2.7983\n",
      "Epoch 101/500\n",
      "11/11 [==============================] - 0s 798us/step - loss: 2.7965\n",
      "Epoch 102/500\n",
      "11/11 [==============================] - 0s 806us/step - loss: 2.7948\n",
      "Epoch 103/500\n",
      "11/11 [==============================] - 0s 798us/step - loss: 2.7931\n",
      "Epoch 104/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.7912\n",
      "Epoch 105/500\n",
      "11/11 [==============================] - 0s 752us/step - loss: 2.7893\n",
      "Epoch 106/500\n",
      "11/11 [==============================] - 0s 900us/step - loss: 2.7877\n",
      "Epoch 107/500\n",
      "11/11 [==============================] - 0s 895us/step - loss: 2.7859\n",
      "Epoch 108/500\n",
      "11/11 [==============================] - 0s 689us/step - loss: 2.7845\n",
      "Epoch 109/500\n",
      "11/11 [==============================] - 0s 898us/step - loss: 2.7827\n",
      "Epoch 110/500\n",
      "11/11 [==============================] - 0s 701us/step - loss: 2.7814\n",
      "Epoch 111/500\n",
      "11/11 [==============================] - 0s 815us/step - loss: 2.7794\n",
      "Epoch 112/500\n",
      "11/11 [==============================] - 0s 798us/step - loss: 2.7779\n",
      "Epoch 113/500\n",
      "11/11 [==============================] - 0s 691us/step - loss: 2.7762\n",
      "Epoch 114/500\n",
      "11/11 [==============================] - 0s 860us/step - loss: 2.7749\n",
      "Epoch 115/500\n",
      "11/11 [==============================] - 0s 709us/step - loss: 2.7732\n",
      "Epoch 116/500\n",
      "11/11 [==============================] - 0s 798us/step - loss: 2.7713\n",
      "Epoch 117/500\n",
      "11/11 [==============================] - 0s 796us/step - loss: 2.7700\n",
      "Epoch 118/500\n",
      "11/11 [==============================] - 0s 797us/step - loss: 2.7684\n",
      "Epoch 119/500\n",
      "11/11 [==============================] - 0s 898us/step - loss: 2.7672\n",
      "Epoch 120/500\n",
      "11/11 [==============================] - 0s 698us/step - loss: 2.7658\n",
      "Epoch 121/500\n",
      "11/11 [==============================] - 0s 798us/step - loss: 2.7642\n",
      "Epoch 122/500\n",
      "11/11 [==============================] - 0s 795us/step - loss: 2.7629\n",
      "Epoch 123/500\n",
      "11/11 [==============================] - 0s 800us/step - loss: 2.7614\n",
      "Epoch 124/500\n",
      "11/11 [==============================] - 0s 999us/step - loss: 2.7600\n",
      "Epoch 125/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.7585\n",
      "Epoch 126/500\n",
      "11/11 [==============================] - 0s 798us/step - loss: 2.7570\n",
      "Epoch 127/500\n",
      "11/11 [==============================] - 0s 898us/step - loss: 2.7553\n",
      "Epoch 128/500\n",
      "11/11 [==============================] - 0s 773us/step - loss: 2.7537\n",
      "Epoch 129/500\n",
      "11/11 [==============================] - 0s 791us/step - loss: 2.7523\n",
      "Epoch 130/500\n",
      "11/11 [==============================] - 0s 898us/step - loss: 2.7508\n",
      "Epoch 131/500\n",
      "11/11 [==============================] - 0s 698us/step - loss: 2.7491\n",
      "Epoch 132/500\n",
      "11/11 [==============================] - 0s 896us/step - loss: 2.7477\n",
      "Epoch 133/500\n",
      "11/11 [==============================] - 0s 698us/step - loss: 2.7462\n",
      "Epoch 134/500\n",
      "11/11 [==============================] - 0s 598us/step - loss: 2.7449\n",
      "Epoch 135/500\n",
      "11/11 [==============================] - 0s 898us/step - loss: 2.7436\n",
      "Epoch 136/500\n",
      "11/11 [==============================] - 0s 606us/step - loss: 2.7419\n",
      "Epoch 137/500\n",
      "11/11 [==============================] - 0s 798us/step - loss: 2.7403\n",
      "Epoch 138/500\n",
      "11/11 [==============================] - 0s 698us/step - loss: 2.7390\n",
      "Epoch 139/500\n",
      "11/11 [==============================] - 0s 698us/step - loss: 2.7374\n",
      "Epoch 140/500\n",
      "11/11 [==============================] - 0s 798us/step - loss: 2.7360\n",
      "Epoch 141/500\n",
      "11/11 [==============================] - 0s 698us/step - loss: 2.7345\n",
      "Epoch 142/500\n",
      "11/11 [==============================] - 0s 900us/step - loss: 2.7330\n",
      "Epoch 143/500\n",
      "11/11 [==============================] - 0s 799us/step - loss: 2.7315\n",
      "Epoch 144/500\n",
      "11/11 [==============================] - 0s 800us/step - loss: 2.7304\n",
      "Epoch 145/500\n",
      "11/11 [==============================] - 0s 997us/step - loss: 2.7287\n",
      "Epoch 146/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.7275\n",
      "Epoch 147/500\n",
      "11/11 [==============================] - 0s 798us/step - loss: 2.7260\n",
      "Epoch 148/500\n",
      "11/11 [==============================] - 0s 799us/step - loss: 2.7247\n",
      "Epoch 149/500\n",
      "11/11 [==============================] - 0s 699us/step - loss: 2.7231\n",
      "Epoch 150/500\n",
      "11/11 [==============================] - 0s 863us/step - loss: 2.7217\n",
      "Epoch 151/500\n",
      "11/11 [==============================] - 0s 698us/step - loss: 2.7203\n",
      "Epoch 152/500\n",
      "11/11 [==============================] - 0s 797us/step - loss: 2.7188\n",
      "Epoch 153/500\n",
      "11/11 [==============================] - 0s 898us/step - loss: 2.7175\n",
      "Epoch 154/500\n",
      "11/11 [==============================] - 0s 915us/step - loss: 2.7162\n",
      "Epoch 155/500\n",
      "11/11 [==============================] - 0s 698us/step - loss: 2.7147\n",
      "Epoch 156/500\n",
      "11/11 [==============================] - 0s 798us/step - loss: 2.7135\n",
      "Epoch 157/500\n",
      "11/11 [==============================] - 0s 776us/step - loss: 2.7123\n",
      "Epoch 158/500\n",
      "11/11 [==============================] - 0s 895us/step - loss: 2.7104\n",
      "Epoch 159/500\n",
      "11/11 [==============================] - 0s 795us/step - loss: 2.7094\n",
      "Epoch 160/500\n",
      "11/11 [==============================] - 0s 995us/step - loss: 2.7076\n",
      "Epoch 161/500\n",
      "11/11 [==============================] - 0s 997us/step - loss: 2.7065\n",
      "Epoch 162/500\n",
      "11/11 [==============================] - 0s 997us/step - loss: 2.7049\n",
      "Epoch 163/500\n",
      "11/11 [==============================] - 0s 848us/step - loss: 2.7037\n",
      "Epoch 164/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.7022\n",
      "Epoch 165/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.7009\n",
      "Epoch 166/500\n",
      "11/11 [==============================] - 0s 997us/step - loss: 2.6996\n",
      "Epoch 167/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.6984\n",
      "Epoch 168/500\n",
      "11/11 [==============================] - 0s 769us/step - loss: 2.6968\n",
      "Epoch 169/500\n",
      "11/11 [==============================] - 0s 975us/step - loss: 2.6953\n",
      "Epoch 170/500\n",
      "11/11 [==============================] - 0s 899us/step - loss: 2.6938\n",
      "Epoch 171/500\n",
      "11/11 [==============================] - 0s 830us/step - loss: 2.6924\n",
      "Epoch 172/500\n",
      "11/11 [==============================] - 0s 796us/step - loss: 2.6909\n",
      "Epoch 173/500\n",
      "11/11 [==============================] - 0s 802us/step - loss: 2.6896\n",
      "Epoch 174/500\n",
      "11/11 [==============================] - 0s 798us/step - loss: 2.6880\n",
      "Epoch 175/500\n",
      "11/11 [==============================] - 0s 895us/step - loss: 2.6869\n",
      "Epoch 176/500\n",
      "11/11 [==============================] - 0s 698us/step - loss: 2.6849\n",
      "Epoch 177/500\n",
      "11/11 [==============================] - 0s 798us/step - loss: 2.6835\n",
      "Epoch 178/500\n",
      "11/11 [==============================] - 0s 798us/step - loss: 2.6821\n",
      "Epoch 179/500\n",
      "11/11 [==============================] - 0s 698us/step - loss: 2.6805\n",
      "Epoch 180/500\n",
      "11/11 [==============================] - 0s 898us/step - loss: 2.6792\n",
      "Epoch 181/500\n",
      "11/11 [==============================] - 0s 636us/step - loss: 2.6777\n",
      "Epoch 182/500\n",
      "11/11 [==============================] - 0s 802us/step - loss: 2.6764\n",
      "Epoch 183/500\n",
      "11/11 [==============================] - 0s 701us/step - loss: 2.6750\n",
      "Epoch 184/500\n",
      "11/11 [==============================] - 0s 997us/step - loss: 2.6734\n",
      "Epoch 185/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.6719\n",
      "Epoch 186/500\n",
      "11/11 [==============================] - 0s 897us/step - loss: 2.6706\n",
      "Epoch 187/500\n",
      "11/11 [==============================] - 0s 895us/step - loss: 2.6690\n",
      "Epoch 188/500\n",
      "11/11 [==============================] - 0s 898us/step - loss: 2.6676\n",
      "Epoch 189/500\n",
      "11/11 [==============================] - 0s 898us/step - loss: 2.6666\n",
      "Epoch 190/500\n",
      "11/11 [==============================] - 0s 997us/step - loss: 2.6650\n",
      "Epoch 191/500\n",
      "11/11 [==============================] - 0s 898us/step - loss: 2.6639\n",
      "Epoch 192/500\n",
      "11/11 [==============================] - 0s 898us/step - loss: 2.6625\n",
      "Epoch 193/500\n",
      "11/11 [==============================] - 0s 798us/step - loss: 2.6608\n",
      "Epoch 194/500\n",
      "11/11 [==============================] - 0s 898us/step - loss: 2.6596\n",
      "Epoch 195/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.6578\n",
      "Epoch 196/500\n",
      "11/11 [==============================] - 0s 997us/step - loss: 2.6565\n",
      "Epoch 197/500\n",
      "11/11 [==============================] - 0s 798us/step - loss: 2.6551\n",
      "Epoch 198/500\n",
      "11/11 [==============================] - 0s 898us/step - loss: 2.6537\n",
      "Epoch 199/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.6521\n",
      "Epoch 200/500\n",
      "11/11 [==============================] - 0s 797us/step - loss: 2.6508\n",
      "Epoch 201/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.6493\n",
      "Epoch 202/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.6480\n",
      "Epoch 203/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.6464\n",
      "Epoch 204/500\n",
      "11/11 [==============================] - 0s 885us/step - loss: 2.6450\n",
      "Epoch 205/500\n",
      "11/11 [==============================] - 0s 798us/step - loss: 2.6436\n",
      "Epoch 206/500\n",
      "11/11 [==============================] - 0s 806us/step - loss: 2.6422\n",
      "Epoch 207/500\n",
      "11/11 [==============================] - 0s 701us/step - loss: 2.6411\n",
      "Epoch 208/500\n",
      "11/11 [==============================] - 0s 898us/step - loss: 2.6396\n",
      "Epoch 209/500\n",
      "11/11 [==============================] - 0s 698us/step - loss: 2.6383\n",
      "Epoch 210/500\n",
      "11/11 [==============================] - 0s 764us/step - loss: 2.6369\n",
      "Epoch 211/500\n",
      "11/11 [==============================] - 0s 698us/step - loss: 2.6354\n",
      "Epoch 212/500\n",
      "11/11 [==============================] - 0s 701us/step - loss: 2.6341\n",
      "Epoch 213/500\n",
      "11/11 [==============================] - 0s 997us/step - loss: 2.6325\n",
      "Epoch 214/500\n",
      "11/11 [==============================] - 0s 598us/step - loss: 2.6309\n",
      "Epoch 215/500\n",
      "11/11 [==============================] - 0s 798us/step - loss: 2.6298\n",
      "Epoch 216/500\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 2.6281\n",
      "Epoch 217/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.6268\n",
      "Epoch 218/500\n",
      "11/11 [==============================] - 0s 896us/step - loss: 2.6253\n",
      "Epoch 219/500\n",
      "11/11 [==============================] - 0s 798us/step - loss: 2.6239\n",
      "Epoch 220/500\n",
      "11/11 [==============================] - 0s 700us/step - loss: 2.6225\n",
      "Epoch 221/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.6210\n",
      "Epoch 222/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.6197\n",
      "Epoch 223/500\n",
      "11/11 [==============================] - 0s 898us/step - loss: 2.6181\n",
      "Epoch 224/500\n",
      "11/11 [==============================] - 0s 898us/step - loss: 2.6168\n",
      "Epoch 225/500\n",
      "11/11 [==============================] - 0s 997us/step - loss: 2.6155\n",
      "Epoch 226/500\n",
      "11/11 [==============================] - 0s 798us/step - loss: 2.6140\n",
      "Epoch 227/500\n",
      "11/11 [==============================] - 0s 797us/step - loss: 2.6127\n",
      "Epoch 228/500\n",
      "11/11 [==============================] - 0s 865us/step - loss: 2.6113\n",
      "Epoch 229/500\n",
      "11/11 [==============================] - 0s 798us/step - loss: 2.6100\n",
      "Epoch 230/500\n",
      "11/11 [==============================] - 0s 798us/step - loss: 2.6087\n",
      "Epoch 231/500\n",
      "11/11 [==============================] - 0s 898us/step - loss: 2.6075\n",
      "Epoch 232/500\n",
      "11/11 [==============================] - 0s 895us/step - loss: 2.6060\n",
      "Epoch 233/500\n",
      "11/11 [==============================] - 0s 901us/step - loss: 2.6048\n",
      "Epoch 234/500\n",
      "11/11 [==============================] - 0s 898us/step - loss: 2.6033\n",
      "Epoch 235/500\n",
      "11/11 [==============================] - 0s 698us/step - loss: 2.6019\n",
      "Epoch 236/500\n",
      "11/11 [==============================] - 0s 898us/step - loss: 2.6005\n",
      "Epoch 237/500\n",
      "11/11 [==============================] - 0s 801us/step - loss: 2.5991\n",
      "Epoch 238/500\n",
      "11/11 [==============================] - 0s 695us/step - loss: 2.5978\n",
      "Epoch 239/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.5962\n",
      "Epoch 240/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.5945\n",
      "Epoch 241/500\n",
      "11/11 [==============================] - 0s 800us/step - loss: 2.5933\n",
      "Epoch 242/500\n",
      "11/11 [==============================] - 0s 798us/step - loss: 2.5917\n",
      "Epoch 243/500\n",
      "11/11 [==============================] - 0s 798us/step - loss: 2.5903\n",
      "Epoch 244/500\n",
      "11/11 [==============================] - 0s 852us/step - loss: 2.5890\n",
      "Epoch 245/500\n",
      "11/11 [==============================] - 0s 798us/step - loss: 2.5878\n",
      "Epoch 246/500\n",
      "11/11 [==============================] - 0s 698us/step - loss: 2.5866\n",
      "Epoch 247/500\n",
      "11/11 [==============================] - 0s 798us/step - loss: 2.5850\n",
      "Epoch 248/500\n",
      "11/11 [==============================] - 0s 693us/step - loss: 2.5838\n",
      "Epoch 249/500\n",
      "11/11 [==============================] - 0s 900us/step - loss: 2.5823\n",
      "Epoch 250/500\n",
      "11/11 [==============================] - 0s 701us/step - loss: 2.5808\n",
      "Epoch 251/500\n",
      "11/11 [==============================] - 0s 798us/step - loss: 2.5794\n",
      "Epoch 252/500\n",
      "11/11 [==============================] - 0s 900us/step - loss: 2.5783\n",
      "Epoch 253/500\n",
      "11/11 [==============================] - 0s 698us/step - loss: 2.5770\n",
      "Epoch 254/500\n",
      "11/11 [==============================] - 0s 795us/step - loss: 2.5754\n",
      "Epoch 255/500\n",
      "11/11 [==============================] - 0s 798us/step - loss: 2.5744\n",
      "Epoch 256/500\n",
      "11/11 [==============================] - 0s 698us/step - loss: 2.5728\n",
      "Epoch 257/500\n",
      "11/11 [==============================] - 0s 799us/step - loss: 2.5718\n",
      "Epoch 258/500\n",
      "11/11 [==============================] - 0s 598us/step - loss: 2.5700\n",
      "Epoch 259/500\n",
      "11/11 [==============================] - 0s 852us/step - loss: 2.5687\n",
      "Epoch 260/500\n",
      "11/11 [==============================] - 0s 798us/step - loss: 2.5676\n",
      "Epoch 261/500\n",
      "11/11 [==============================] - 0s 898us/step - loss: 2.5660\n",
      "Epoch 262/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.5645\n",
      "Epoch 263/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.5634\n",
      "Epoch 264/500\n",
      "11/11 [==============================] - 0s 798us/step - loss: 2.5620\n",
      "Epoch 265/500\n",
      "11/11 [==============================] - 0s 701us/step - loss: 2.5605\n",
      "Epoch 266/500\n",
      "11/11 [==============================] - 0s 895us/step - loss: 2.5593\n",
      "Epoch 267/500\n",
      "11/11 [==============================] - 0s 792us/step - loss: 2.5580\n",
      "Epoch 268/500\n",
      "11/11 [==============================] - 0s 800us/step - loss: 2.5565\n",
      "Epoch 269/500\n",
      "11/11 [==============================] - 0s 702us/step - loss: 2.5556\n",
      "Epoch 270/500\n",
      "11/11 [==============================] - 0s 795us/step - loss: 2.5541\n",
      "Epoch 271/500\n",
      "11/11 [==============================] - 0s 998us/step - loss: 2.5528\n",
      "Epoch 272/500\n",
      "11/11 [==============================] - 0s 696us/step - loss: 2.5517\n",
      "Epoch 273/500\n",
      "11/11 [==============================] - 0s 897us/step - loss: 2.5504\n",
      "Epoch 274/500\n",
      "11/11 [==============================] - 0s 797us/step - loss: 2.5489\n",
      "Epoch 275/500\n",
      "11/11 [==============================] - 0s 698us/step - loss: 2.5477\n",
      "Epoch 276/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.5463\n",
      "Epoch 277/500\n",
      "11/11 [==============================] - 0s 896us/step - loss: 2.5451\n",
      "Epoch 278/500\n",
      "11/11 [==============================] - 0s 900us/step - loss: 2.5439\n",
      "Epoch 279/500\n",
      "11/11 [==============================] - 0s 894us/step - loss: 2.5424\n",
      "Epoch 280/500\n",
      "11/11 [==============================] - 0s 980us/step - loss: 2.5413\n",
      "Epoch 281/500\n",
      "11/11 [==============================] - 0s 997us/step - loss: 2.5397\n",
      "Epoch 282/500\n",
      "11/11 [==============================] - 0s 997us/step - loss: 2.5385\n",
      "Epoch 283/500\n",
      "11/11 [==============================] - 0s 898us/step - loss: 2.5371\n",
      "Epoch 284/500\n",
      "11/11 [==============================] - 0s 798us/step - loss: 2.5359\n",
      "Epoch 285/500\n",
      "11/11 [==============================] - 0s 798us/step - loss: 2.5346\n",
      "Epoch 286/500\n",
      "11/11 [==============================] - 0s 916us/step - loss: 2.5334\n",
      "Epoch 287/500\n",
      "11/11 [==============================] - 0s 798us/step - loss: 2.5322\n",
      "Epoch 288/500\n",
      "11/11 [==============================] - 0s 897us/step - loss: 2.5308\n",
      "Epoch 289/500\n",
      "11/11 [==============================] - 0s 898us/step - loss: 2.5293\n",
      "Epoch 290/500\n",
      "11/11 [==============================] - 0s 799us/step - loss: 2.5281\n",
      "Epoch 291/500\n",
      "11/11 [==============================] - 0s 898us/step - loss: 2.5270\n",
      "Epoch 292/500\n",
      "11/11 [==============================] - 0s 882us/step - loss: 2.5258\n",
      "Epoch 293/500\n",
      "11/11 [==============================] - 0s 798us/step - loss: 2.5244\n",
      "Epoch 294/500\n",
      "11/11 [==============================] - 0s 898us/step - loss: 2.5232\n",
      "Epoch 295/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.5219\n",
      "Epoch 296/500\n",
      "11/11 [==============================] - 0s 798us/step - loss: 2.5208\n",
      "Epoch 297/500\n",
      "11/11 [==============================] - 0s 897us/step - loss: 2.5194\n",
      "Epoch 298/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.5183\n",
      "Epoch 299/500\n",
      "11/11 [==============================] - 0s 898us/step - loss: 2.5174\n",
      "Epoch 300/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.5163\n",
      "Epoch 301/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.5150\n",
      "Epoch 302/500\n",
      "11/11 [==============================] - 0s 997us/step - loss: 2.5138\n",
      "Epoch 303/500\n",
      "11/11 [==============================] - 0s 798us/step - loss: 2.5126\n",
      "Epoch 304/500\n",
      "11/11 [==============================] - 0s 798us/step - loss: 2.5115\n",
      "Epoch 305/500\n",
      "11/11 [==============================] - 0s 899us/step - loss: 2.5101\n",
      "Epoch 306/500\n",
      "11/11 [==============================] - 0s 997us/step - loss: 2.5089\n",
      "Epoch 307/500\n",
      "11/11 [==============================] - 0s 881us/step - loss: 2.5074\n",
      "Epoch 308/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.5063\n",
      "Epoch 309/500\n",
      "11/11 [==============================] - 0s 898us/step - loss: 2.5051\n",
      "Epoch 310/500\n",
      "11/11 [==============================] - 0s 898us/step - loss: 2.5037\n",
      "Epoch 311/500\n",
      "11/11 [==============================] - 0s 997us/step - loss: 2.5025\n",
      "Epoch 312/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.5014\n",
      "Epoch 313/500\n",
      "11/11 [==============================] - 0s 880us/step - loss: 2.5001\n",
      "Epoch 314/500\n",
      "11/11 [==============================] - 0s 698us/step - loss: 2.4991\n",
      "Epoch 315/500\n",
      "11/11 [==============================] - 0s 798us/step - loss: 2.4978\n",
      "Epoch 316/500\n",
      "11/11 [==============================] - 0s 698us/step - loss: 2.4967\n",
      "Epoch 317/500\n",
      "11/11 [==============================] - 0s 894us/step - loss: 2.4954\n",
      "Epoch 318/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.4942\n",
      "Epoch 319/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.4933\n",
      "Epoch 320/500\n",
      "11/11 [==============================] - 0s 898us/step - loss: 2.4921\n",
      "Epoch 321/500\n",
      "11/11 [==============================] - 0s 891us/step - loss: 2.4910\n",
      "Epoch 322/500\n",
      "11/11 [==============================] - 0s 898us/step - loss: 2.4897\n",
      "Epoch 323/500\n",
      "11/11 [==============================] - 0s 800us/step - loss: 2.4885\n",
      "Epoch 324/500\n",
      "11/11 [==============================] - 0s 798us/step - loss: 2.4873\n",
      "Epoch 325/500\n",
      "11/11 [==============================] - 0s 754us/step - loss: 2.4863\n",
      "Epoch 326/500\n",
      "11/11 [==============================] - 0s 798us/step - loss: 2.4852\n",
      "Epoch 327/500\n",
      "11/11 [==============================] - 0s 881us/step - loss: 2.4840\n",
      "Epoch 328/500\n",
      "11/11 [==============================] - 0s 897us/step - loss: 2.4830\n",
      "Epoch 329/500\n",
      "11/11 [==============================] - 0s 901us/step - loss: 2.4820\n",
      "Epoch 330/500\n",
      "11/11 [==============================] - 0s 801us/step - loss: 2.4806\n",
      "Epoch 331/500\n",
      "11/11 [==============================] - 0s 799us/step - loss: 2.4794\n",
      "Epoch 332/500\n",
      "11/11 [==============================] - 0s 898us/step - loss: 2.4780\n",
      "Epoch 333/500\n",
      "11/11 [==============================] - 0s 898us/step - loss: 2.4772\n",
      "Epoch 334/500\n",
      "11/11 [==============================] - 0s 798us/step - loss: 2.4758\n",
      "Epoch 335/500\n",
      "11/11 [==============================] - 0s 898us/step - loss: 2.4749\n",
      "Epoch 336/500\n",
      "11/11 [==============================] - 0s 698us/step - loss: 2.4737\n",
      "Epoch 337/500\n",
      "11/11 [==============================] - 0s 892us/step - loss: 2.4726\n",
      "Epoch 338/500\n",
      "11/11 [==============================] - 0s 898us/step - loss: 2.4714\n",
      "Epoch 339/500\n",
      "11/11 [==============================] - 0s 891us/step - loss: 2.4705\n",
      "Epoch 340/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.4694\n",
      "Epoch 341/500\n",
      "11/11 [==============================] - 0s 898us/step - loss: 2.4683\n",
      "Epoch 342/500\n",
      "11/11 [==============================] - 0s 698us/step - loss: 2.4673\n",
      "Epoch 343/500\n",
      "11/11 [==============================] - 0s 820us/step - loss: 2.4664\n",
      "Epoch 344/500\n",
      "11/11 [==============================] - 0s 798us/step - loss: 2.4656\n",
      "Epoch 345/500\n",
      "11/11 [==============================] - 0s 719us/step - loss: 2.4643\n",
      "Epoch 346/500\n",
      "11/11 [==============================] - 0s 895us/step - loss: 2.4633\n",
      "Epoch 347/500\n",
      "11/11 [==============================] - 0s 698us/step - loss: 2.4622\n",
      "Epoch 348/500\n",
      "11/11 [==============================] - 0s 798us/step - loss: 2.4612\n",
      "Epoch 349/500\n",
      "11/11 [==============================] - 0s 999us/step - loss: 2.4603\n",
      "Epoch 350/500\n",
      "11/11 [==============================] - 0s 701us/step - loss: 2.4592\n",
      "Epoch 351/500\n",
      "11/11 [==============================] - 0s 913us/step - loss: 2.4581\n",
      "Epoch 352/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.4572\n",
      "Epoch 353/500\n",
      "11/11 [==============================] - 0s 886us/step - loss: 2.4562\n",
      "Epoch 354/500\n",
      "11/11 [==============================] - 0s 827us/step - loss: 2.4551\n",
      "Epoch 355/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.4538\n",
      "Epoch 356/500\n",
      "11/11 [==============================] - 0s 796us/step - loss: 2.4531\n",
      "Epoch 357/500\n",
      "11/11 [==============================] - 0s 898us/step - loss: 2.4521\n",
      "Epoch 358/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.4516\n",
      "Epoch 359/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.4503\n",
      "Epoch 360/500\n",
      "11/11 [==============================] - 0s 898us/step - loss: 2.4494\n",
      "Epoch 361/500\n",
      "11/11 [==============================] - 0s 899us/step - loss: 2.4488\n",
      "Epoch 362/500\n",
      "11/11 [==============================] - 0s 898us/step - loss: 2.4478\n",
      "Epoch 363/500\n",
      "11/11 [==============================] - 0s 701us/step - loss: 2.4469\n",
      "Epoch 364/500\n",
      "11/11 [==============================] - 0s 898us/step - loss: 2.4459\n",
      "Epoch 365/500\n",
      "11/11 [==============================] - 0s 898us/step - loss: 2.4451\n",
      "Epoch 366/500\n",
      "11/11 [==============================] - 0s 800us/step - loss: 2.4439\n",
      "Epoch 367/500\n",
      "11/11 [==============================] - 0s 894us/step - loss: 2.4432\n",
      "Epoch 368/500\n",
      "11/11 [==============================] - 0s 899us/step - loss: 2.4423\n",
      "Epoch 369/500\n",
      "11/11 [==============================] - 0s 798us/step - loss: 2.4413\n",
      "Epoch 370/500\n",
      "11/11 [==============================] - 0s 900us/step - loss: 2.4403\n",
      "Epoch 371/500\n",
      "11/11 [==============================] - 0s 698us/step - loss: 2.4392\n",
      "Epoch 372/500\n",
      "11/11 [==============================] - 0s 798us/step - loss: 2.4383\n",
      "Epoch 373/500\n",
      "11/11 [==============================] - 0s 796us/step - loss: 2.4377\n",
      "Epoch 374/500\n",
      "11/11 [==============================] - 0s 698us/step - loss: 2.4368\n",
      "Epoch 375/500\n",
      "11/11 [==============================] - 0s 900us/step - loss: 2.4359\n",
      "Epoch 376/500\n",
      "11/11 [==============================] - 0s 808us/step - loss: 2.4350\n",
      "Epoch 377/500\n",
      "11/11 [==============================] - 0s 997us/step - loss: 2.4342\n",
      "Epoch 378/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.4335\n",
      "Epoch 379/500\n",
      "11/11 [==============================] - 0s 698us/step - loss: 2.4326\n",
      "Epoch 380/500\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 2.4316\n",
      "Epoch 381/500\n",
      "11/11 [==============================] - 0s 983us/step - loss: 2.4306\n",
      "Epoch 382/500\n",
      "11/11 [==============================] - 0s 698us/step - loss: 2.4301\n",
      "Epoch 383/500\n",
      "11/11 [==============================] - 0s 895us/step - loss: 2.4289\n",
      "Epoch 384/500\n",
      "11/11 [==============================] - 0s 698us/step - loss: 2.4282\n",
      "Epoch 385/500\n",
      "11/11 [==============================] - 0s 798us/step - loss: 2.4276\n",
      "Epoch 386/500\n",
      "11/11 [==============================] - 0s 898us/step - loss: 2.4267\n",
      "Epoch 387/500\n",
      "11/11 [==============================] - 0s 698us/step - loss: 2.4259\n",
      "Epoch 388/500\n",
      "11/11 [==============================] - 0s 698us/step - loss: 2.4251\n",
      "Epoch 389/500\n",
      "11/11 [==============================] - 0s 798us/step - loss: 2.4244\n",
      "Epoch 390/500\n",
      "11/11 [==============================] - 0s 698us/step - loss: 2.4234\n",
      "Epoch 391/500\n",
      "11/11 [==============================] - 0s 798us/step - loss: 2.4225\n",
      "Epoch 392/500\n",
      "11/11 [==============================] - 0s 798us/step - loss: 2.4217\n",
      "Epoch 393/500\n",
      "11/11 [==============================] - 0s 800us/step - loss: 2.4211\n",
      "Epoch 394/500\n",
      "11/11 [==============================] - 0s 898us/step - loss: 2.4201\n",
      "Epoch 395/500\n",
      "11/11 [==============================] - 0s 798us/step - loss: 2.4192\n",
      "Epoch 396/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.4181\n",
      "Epoch 397/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.4175\n",
      "Epoch 398/500\n",
      "11/11 [==============================] - 0s 944us/step - loss: 2.4168\n",
      "Epoch 399/500\n",
      "11/11 [==============================] - 0s 798us/step - loss: 2.4160\n",
      "Epoch 400/500\n",
      "11/11 [==============================] - 0s 798us/step - loss: 2.4152\n",
      "Epoch 401/500\n",
      "11/11 [==============================] - 0s 898us/step - loss: 2.4144\n",
      "Epoch 402/500\n",
      "11/11 [==============================] - 0s 798us/step - loss: 2.4136\n",
      "Epoch 403/500\n",
      "11/11 [==============================] - 0s 997us/step - loss: 2.4128\n",
      "Epoch 404/500\n",
      "11/11 [==============================] - 0s 798us/step - loss: 2.4120\n",
      "Epoch 405/500\n",
      "11/11 [==============================] - 0s 798us/step - loss: 2.4114\n",
      "Epoch 406/500\n",
      "11/11 [==============================] - 0s 895us/step - loss: 2.4105\n",
      "Epoch 407/500\n",
      "11/11 [==============================] - 0s 699us/step - loss: 2.4098\n",
      "Epoch 408/500\n",
      "11/11 [==============================] - 0s 798us/step - loss: 2.4088\n",
      "Epoch 409/500\n",
      "11/11 [==============================] - 0s 895us/step - loss: 2.4082\n",
      "Epoch 410/500\n",
      "11/11 [==============================] - 0s 798us/step - loss: 2.4077\n",
      "Epoch 411/500\n",
      "11/11 [==============================] - 0s 891us/step - loss: 2.4070\n",
      "Epoch 412/500\n",
      "11/11 [==============================] - 0s 699us/step - loss: 2.4062\n",
      "Epoch 413/500\n",
      "11/11 [==============================] - 0s 896us/step - loss: 2.4055\n",
      "Epoch 414/500\n",
      "11/11 [==============================] - 0s 898us/step - loss: 2.4046\n",
      "Epoch 415/500\n",
      "11/11 [==============================] - 0s 798us/step - loss: 2.4039\n",
      "Epoch 416/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.4030\n",
      "Epoch 417/500\n",
      "11/11 [==============================] - 0s 997us/step - loss: 2.4023\n",
      "Epoch 418/500\n",
      "11/11 [==============================] - 0s 898us/step - loss: 2.4017\n",
      "Epoch 419/500\n",
      "11/11 [==============================] - 0s 798us/step - loss: 2.4009\n",
      "Epoch 420/500\n",
      "11/11 [==============================] - 0s 997us/step - loss: 2.4001\n",
      "Epoch 421/500\n",
      "11/11 [==============================] - 0s 785us/step - loss: 2.3993\n",
      "Epoch 422/500\n",
      "11/11 [==============================] - 0s 698us/step - loss: 2.3988\n",
      "Epoch 423/500\n",
      "11/11 [==============================] - 0s 898us/step - loss: 2.3981\n",
      "Epoch 424/500\n",
      "11/11 [==============================] - 0s 894us/step - loss: 2.3977\n",
      "Epoch 425/500\n",
      "11/11 [==============================] - 0s 849us/step - loss: 2.3966\n",
      "Epoch 426/500\n",
      "11/11 [==============================] - 0s 798us/step - loss: 2.3962\n",
      "Epoch 427/500\n",
      "11/11 [==============================] - 0s 797us/step - loss: 2.3957\n",
      "Epoch 428/500\n",
      "11/11 [==============================] - 0s 981us/step - loss: 2.3946\n",
      "Epoch 429/500\n",
      "11/11 [==============================] - 0s 698us/step - loss: 2.3938\n",
      "Epoch 430/500\n",
      "11/11 [==============================] - 0s 898us/step - loss: 2.3935\n",
      "Epoch 431/500\n",
      "11/11 [==============================] - 0s 897us/step - loss: 2.3926\n",
      "Epoch 432/500\n",
      "11/11 [==============================] - 0s 701us/step - loss: 2.3920\n",
      "Epoch 433/500\n",
      "11/11 [==============================] - 0s 798us/step - loss: 2.3915\n",
      "Epoch 434/500\n",
      "11/11 [==============================] - 0s 798us/step - loss: 2.3909\n",
      "Epoch 435/500\n",
      "11/11 [==============================] - 0s 898us/step - loss: 2.3899\n",
      "Epoch 436/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.3898\n",
      "Epoch 437/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.3890\n",
      "Epoch 438/500\n",
      "11/11 [==============================] - 0s 997us/step - loss: 2.3882\n",
      "Epoch 439/500\n",
      "11/11 [==============================] - 0s 695us/step - loss: 2.3875\n",
      "Epoch 440/500\n",
      "11/11 [==============================] - 0s 901us/step - loss: 2.3869\n",
      "Epoch 441/500\n",
      "11/11 [==============================] - 0s 755us/step - loss: 2.3862\n",
      "Epoch 442/500\n",
      "11/11 [==============================] - 0s 901us/step - loss: 2.3856\n",
      "Epoch 443/500\n",
      "11/11 [==============================] - 0s 898us/step - loss: 2.3850\n",
      "Epoch 444/500\n",
      "11/11 [==============================] - 0s 698us/step - loss: 2.3844\n",
      "Epoch 445/500\n",
      "11/11 [==============================] - 0s 919us/step - loss: 2.3837\n",
      "Epoch 446/500\n",
      "11/11 [==============================] - 0s 898us/step - loss: 2.3832\n",
      "Epoch 447/500\n",
      "11/11 [==============================] - 0s 898us/step - loss: 2.3824\n",
      "Epoch 448/500\n",
      "11/11 [==============================] - 0s 900us/step - loss: 2.3819\n",
      "Epoch 449/500\n",
      "11/11 [==============================] - 0s 798us/step - loss: 2.3815\n",
      "Epoch 450/500\n",
      "11/11 [==============================] - 0s 798us/step - loss: 2.3805\n",
      "Epoch 451/500\n",
      "11/11 [==============================] - 0s 897us/step - loss: 2.3801\n",
      "Epoch 452/500\n",
      "11/11 [==============================] - 0s 698us/step - loss: 2.3794\n",
      "Epoch 453/500\n",
      "11/11 [==============================] - 0s 800us/step - loss: 2.3787\n",
      "Epoch 454/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.3781\n",
      "Epoch 455/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.3775\n",
      "Epoch 456/500\n",
      "11/11 [==============================] - 0s 966us/step - loss: 2.3770\n",
      "Epoch 457/500\n",
      "11/11 [==============================] - 0s 798us/step - loss: 2.3762\n",
      "Epoch 458/500\n",
      "11/11 [==============================] - 0s 941us/step - loss: 2.3756\n",
      "Epoch 459/500\n",
      "11/11 [==============================] - 0s 698us/step - loss: 2.3750\n",
      "Epoch 460/500\n",
      "11/11 [==============================] - 0s 798us/step - loss: 2.3745\n",
      "Epoch 461/500\n",
      "11/11 [==============================] - 0s 698us/step - loss: 2.3737\n",
      "Epoch 462/500\n",
      "11/11 [==============================] - 0s 698us/step - loss: 2.3731\n",
      "Epoch 463/500\n",
      "11/11 [==============================] - 0s 999us/step - loss: 2.3727\n",
      "Epoch 464/500\n",
      "11/11 [==============================] - 0s 788us/step - loss: 2.3720\n",
      "Epoch 465/500\n",
      "11/11 [==============================] - 0s 993us/step - loss: 2.3714\n",
      "Epoch 466/500\n",
      "11/11 [==============================] - 0s 799us/step - loss: 2.3706\n",
      "Epoch 467/500\n",
      "11/11 [==============================] - 0s 698us/step - loss: 2.3701\n",
      "Epoch 468/500\n",
      "11/11 [==============================] - 0s 895us/step - loss: 2.3695\n",
      "Epoch 469/500\n",
      "11/11 [==============================] - 0s 698us/step - loss: 2.3693\n",
      "Epoch 470/500\n",
      "11/11 [==============================] - 0s 798us/step - loss: 2.3685\n",
      "Epoch 471/500\n",
      "11/11 [==============================] - 0s 997us/step - loss: 2.3679\n",
      "Epoch 472/500\n",
      "11/11 [==============================] - 0s 798us/step - loss: 2.3675\n",
      "Epoch 473/500\n",
      "11/11 [==============================] - 0s 945us/step - loss: 2.3670\n",
      "Epoch 474/500\n",
      "11/11 [==============================] - 0s 997us/step - loss: 2.3665\n",
      "Epoch 475/500\n",
      "11/11 [==============================] - 0s 999us/step - loss: 2.3657\n",
      "Epoch 476/500\n",
      "11/11 [==============================] - 0s 898us/step - loss: 2.3653\n",
      "Epoch 477/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.3647\n",
      "Epoch 478/500\n",
      "11/11 [==============================] - 0s 802us/step - loss: 2.3640\n",
      "Epoch 479/500\n",
      "11/11 [==============================] - 0s 698us/step - loss: 2.3638\n",
      "Epoch 480/500\n",
      "11/11 [==============================] - 0s 901us/step - loss: 2.3631\n",
      "Epoch 481/500\n",
      "11/11 [==============================] - 0s 793us/step - loss: 2.3624\n",
      "Epoch 482/500\n",
      "11/11 [==============================] - 0s 851us/step - loss: 2.3619\n",
      "Epoch 483/500\n",
      "11/11 [==============================] - 0s 851us/step - loss: 2.3613\n",
      "Epoch 484/500\n",
      "11/11 [==============================] - 0s 698us/step - loss: 2.3610\n",
      "Epoch 485/500\n",
      "11/11 [==============================] - 0s 895us/step - loss: 2.3606\n",
      "Epoch 486/500\n",
      "11/11 [==============================] - 0s 698us/step - loss: 2.3600\n",
      "Epoch 487/500\n",
      "11/11 [==============================] - 0s 877us/step - loss: 2.3595\n",
      "Epoch 488/500\n",
      "11/11 [==============================] - 0s 787us/step - loss: 2.3589\n",
      "Epoch 489/500\n",
      "11/11 [==============================] - 0s 798us/step - loss: 2.3585\n",
      "Epoch 490/500\n",
      "11/11 [==============================] - 0s 891us/step - loss: 2.3581\n",
      "Epoch 491/500\n",
      "11/11 [==============================] - 0s 695us/step - loss: 2.3577\n",
      "Epoch 492/500\n",
      "11/11 [==============================] - 0s 798us/step - loss: 2.3570\n",
      "Epoch 493/500\n",
      "11/11 [==============================] - 0s 949us/step - loss: 2.3564\n",
      "Epoch 494/500\n",
      "11/11 [==============================] - 0s 917us/step - loss: 2.3559\n",
      "Epoch 495/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.3552\n",
      "Epoch 496/500\n",
      "11/11 [==============================] - 0s 997us/step - loss: 2.3547\n",
      "Epoch 497/500\n",
      "11/11 [==============================] - 0s 900us/step - loss: 2.3542\n",
      "Epoch 498/500\n",
      "11/11 [==============================] - 0s 700us/step - loss: 2.3537\n",
      "Epoch 499/500\n",
      "11/11 [==============================] - 0s 796us/step - loss: 2.3533\n",
      "Epoch 500/500\n",
      "11/11 [==============================] - 0s 798us/step - loss: 2.3527\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a1ba304940>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CreateModel()\n",
    "# Optimizing the network weights\n",
    "model.fit(x=XX, y=YY, batch_size=10, epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19d18d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21, 2)\n",
      "-1.3235352\n",
      "[[-1.613885    0.17449677]\n",
      " [ 1.4671553  -1.3235352 ]\n",
      " [ 0.1650999  -0.9315504 ]\n",
      " [ 0.85392195  0.8085883 ]\n",
      " [-1.9027175   1.2868837 ]\n",
      " [ 0.5412559   1.0760299 ]\n",
      " [ 0.11879098 -1.3585513 ]\n",
      " [ 0.95871425  0.77462554]\n",
      " [ 0.10023533 -0.7401052 ]\n",
      " [ 1.9945936  -1.0369549 ]\n",
      " [-0.20707697 -1.1891186 ]\n",
      " [ 0.8307448  -0.03291896]\n",
      " [-1.3777212  -0.8106481 ]\n",
      " [-0.46663186  0.8495313 ]\n",
      " [ 0.21958198  0.70498455]\n",
      " [ 1.080116    0.8149148 ]\n",
      " [ 0.15476292  0.7409237 ]\n",
      " [ 1.0004083  -1.4575133 ]\n",
      " [ 1.8120517  -2.2360523 ]\n",
      " [ 0.3620179   0.89346546]\n",
      " [-0.9493005  -0.21866085]]\n"
     ]
    }
   ],
   "source": [
    "weights = model.get_weights()[0] #21*2\n",
    "print(weights.shape)\n",
    "print(weights[1][1])\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0bed43c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'beautiful': array([-1.613885  ,  0.17449677], dtype=float32), 'boy': array([ 1.4671553, -1.3235352], dtype=float32), 'can': array([ 0.1650999, -0.9315504], dtype=float32), 'children': array([0.85392195, 0.8085883 ], dtype=float32), 'daughter': array([-1.9027175,  1.2868837], dtype=float32), 'family': array([0.5412559, 1.0760299], dtype=float32), 'future': array([ 0.11879098, -1.3585513 ], dtype=float32), 'king': array([0.95871425, 0.77462554], dtype=float32), 'man': array([ 0.10023533, -0.7401052 ], dtype=float32), 'now': array([ 1.9945936, -1.0369549], dtype=float32), 'only': array([-0.20707697, -1.1891186 ], dtype=float32), 'prince': array([ 0.8307448 , -0.03291896], dtype=float32), 'princess': array([-1.3777212, -0.8106481], dtype=float32), 'queen': array([-0.46663186,  0.8495313 ], dtype=float32), 'realm': array([0.21958198, 0.70498455], dtype=float32), 'royal': array([1.080116 , 0.8149148], dtype=float32), 'rule': array([0.15476292, 0.7409237 ], dtype=float32), 'son': array([ 1.0004083, -1.4575133], dtype=float32), 'strong': array([ 1.8120517, -2.2360523], dtype=float32), 'their': array([0.3620179 , 0.89346546], dtype=float32), 'woman': array([-0.9493005 , -0.21866085], dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "embedding_dict = {}\n",
    "for word in words: #to pick the a row of weight of two values for each unique word since weights = 21*2\n",
    "    embedding_dict.update({\n",
    "        word: weights[unique_word_dict.get(word)]\n",
    "    })\n",
    "\n",
    "print(embedding_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f917163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.95871425, 0.77462554], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_dict['king']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3d0952d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "def document_similarity(doc1, doc2):\n",
    "    doc1 = list(text_preprocessing(doc1))\n",
    "    doc2 = list(text_preprocessing(doc2))\n",
    "    sims = np.zeros(len(doc2))\n",
    "    summ = 0\n",
    "    for i in range(len(doc1)):\n",
    "        x = embedding_dict[doc1[i]]\n",
    "        for j in range(len(doc2)):\n",
    "            y = embedding_dict[doc2[j]]\n",
    "            sims[j] = cosine(x, y) - 1\n",
    "        summ += np.max(sims)\n",
    "    return summ/len(doc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d7b7bd25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8230771025021871\n"
     ]
    }
   ],
   "source": [
    "doc1 = \"The future king is the prince\"\n",
    "doc2 = \"Daughter is the princess\"\n",
    "print(document_similarity(doc1, doc2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eba6a3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
